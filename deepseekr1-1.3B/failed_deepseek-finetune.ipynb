{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install torch numpy pandas datasets transformers peft tqdm evaluate matplotlib scikit-learn bitsandbytes","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y2t4M067zJV4","outputId":"5cb86691-dbff-4e24-c4c0-dedee0952b2b","trusted":true,"execution":{"iopub.status.busy":"2025-03-20T14:33:40.999516Z","iopub.execute_input":"2025-03-20T14:33:40.999839Z","iopub.status.idle":"2025-03-20T14:33:44.450931Z","shell.execute_reply.started":"2025-03-20T14:33:40.999804Z","shell.execute_reply":"2025-03-20T14:33:44.449856Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.3)\nRequirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.3.1)\nRequirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.0)\nRequirement already satisfied: peft in /usr/local/lib/python3.10/dist-packages (0.14.0)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.67.1)\nRequirement already satisfied: evaluate in /usr/local/lib/python3.10/dist-packages (0.4.3)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.5)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\nRequirement already satisfied: bitsandbytes in /usr/local/lib/python3.10/dist-packages (0.45.3)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.17.0)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.12.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy) (2.4.1)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2025.1)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2025.1)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (19.0.1)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\nRequirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.12)\nRequirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.29.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\nRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft) (5.9.5)\nRequirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from peft) (1.2.1)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.55.3)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (11.0.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.0)\nRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.6)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.2)\nRequirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (5.0.1)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (25.1.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy) (2024.2.0)\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# DeepSeek R1 1B Fine-tuning on KodCode Dataset\n# Setup and Dependencies\n\nimport os\nimport torch\nimport numpy as np\nimport pandas as pd\nfrom datasets import load_dataset\nfrom transformers import (\n    AutoModelForCausalLM,\n    AutoTokenizer,\n    TrainingArguments,\n    Trainer,\n    DataCollatorForLanguageModeling,\n    EarlyStoppingCallback\n)\nfrom peft import (\n    LoraConfig,\n    get_peft_model,\n    prepare_model_for_kbit_training,\n    TaskType\n)\nfrom tqdm import tqdm\nimport evaluate\nimport gc\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nimport bitsandbytes as bnb","metadata":{"id":"_1_S_3PZy7eN","trusted":true,"execution":{"iopub.status.busy":"2025-03-20T14:33:44.452541Z","iopub.execute_input":"2025-03-20T14:33:44.452910Z","iopub.status.idle":"2025-03-20T14:34:07.135745Z","shell.execute_reply.started":"2025-03-20T14:33:44.452872Z","shell.execute_reply":"2025-03-20T14:34:07.135100Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# Check if GPU is available\nprint(f\"CUDA available: {torch.cuda.is_available()}\")\nif torch.cuda.is_available():\n    torch.cuda.empty_cache()\n    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n    print(f\"Memory allocated: {torch.cuda.memory_allocated(0)/1e9:.2f} GB\")\n    print(f\"Memory reserved: {torch.cuda.memory_reserved(0)/1e9:.2f} GB\")","metadata":{"id":"KXBUJzGgz84F","trusted":true,"execution":{"iopub.status.busy":"2025-03-20T14:34:07.137474Z","iopub.execute_input":"2025-03-20T14:34:07.138142Z","iopub.status.idle":"2025-03-20T14:34:07.144173Z","shell.execute_reply.started":"2025-03-20T14:34:07.138118Z","shell.execute_reply":"2025-03-20T14:34:07.143352Z"}},"outputs":[{"name":"stdout","text":"CUDA available: True\nGPU: Tesla P100-PCIE-16GB\nMemory allocated: 0.00 GB\nMemory reserved: 0.00 GB\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# Load the dataset\nprint(\"Loading KodCode dataset...\")\ndataset = load_dataset(\"KodCode/KodCode-V1-SFT-R1\")\nprint(f\"Dataset loaded with {len(dataset['train'])} samples\")","metadata":{"id":"s60x_9pR3En2","trusted":true,"execution":{"iopub.status.busy":"2025-03-20T14:34:07.145472Z","iopub.execute_input":"2025-03-20T14:34:07.145779Z","iopub.status.idle":"2025-03-20T14:36:14.601723Z","shell.execute_reply.started":"2025-03-20T14:34:07.145750Z","shell.execute_reply":"2025-03-20T14:36:14.600951Z"}},"outputs":[{"name":"stdout","text":"Loading KodCode dataset...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/6.47k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7863b0a7644349439e10ad25dca983d8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00000-of-00011.parquet:   0%|          | 0.00/217M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1e0d44960dd341229d3916e572249d3f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00001-of-00011.parquet:   0%|          | 0.00/227M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0964d299a05b453a8628186e43c297a7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00002-of-00011.parquet:   0%|          | 0.00/297M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ed9b926b7aeb4e2d9fe7defe8d66a379"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00003-of-00011.parquet:   0%|          | 0.00/138M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4c930af50eca48ff8cb1fc2bd253df4f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00004-of-00011.parquet:   0%|          | 0.00/137M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b5bfb3701c214ee691457f3b76a6f986"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00005-of-00011.parquet:   0%|          | 0.00/228M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dfc6682504304a8a9ac29e443f764209"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00006-of-00011.parquet:   0%|          | 0.00/239M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3a00897fe4f7432e89c59c19360e34ef"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00007-of-00011.parquet:   0%|          | 0.00/239M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eff36a77ff8643f0a470b05652ee695e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00008-of-00011.parquet:   0%|          | 0.00/222M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6f25fbab53084016ac78203ea88f0d09"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00009-of-00011.parquet:   0%|          | 0.00/167M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"094808876f41496880091b89a5ebf0f4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00010-of-00011.parquet:   0%|          | 0.00/210M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3532fc78374940978f628a25dd73847f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"incorrect-00000-of-00011.parquet:   0%|          | 0.00/216M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c58d6fb7e2454e168de03849a0a19bed"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"incorrect-00001-of-00011.parquet:   0%|          | 0.00/233M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6e72b7bd597f45f2893ca8621bb72bf0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"incorrect-00002-of-00011.parquet:   0%|          | 0.00/232M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8e221dcb89174bb4938f291ed3896b3a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"incorrect-00003-of-00011.parquet:   0%|          | 0.00/226M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"83b3a709f6404ff39a6cde0f183cc619"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"incorrect-00004-of-00011.parquet:   0%|          | 0.00/287M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"94ab1835566b40dda2fcaea64cdfa99a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"incorrect-00005-of-00011.parquet:   0%|          | 0.00/182M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f20e1e391b2245e2a3bf6e619b60ca85"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"incorrect-00006-of-00011.parquet:   0%|          | 0.00/102M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"736a20fd7e1e46a6b9e2fa841280aa97"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"incorrect-00007-of-00011.parquet:   0%|          | 0.00/122M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2064b2403d984a8d9bf40ecc1862d4fd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"incorrect-00008-of-00011.parquet:   0%|          | 0.00/269M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0ca0d1f9f177409fa3735ebb787e3bbe"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"incorrect-00009-of-00011.parquet:   0%|          | 0.00/175M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8e883b772c7741388a00e83286cebdb5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"incorrect-00010-of-00011.parquet:   0%|          | 0.00/213M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"081e50cbc6de4204b41fc0b27c0826d6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"use_with_caution-00000-of-00001.parquet:   0%|          | 0.00/39.4M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e94cca5485514b358043d211b6183533"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/268211 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"022b9210d0774efdadc97b87a9b5b111"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating incorrect split:   0%|          | 0/210787 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5b7e1c9a73be4393b92544e3bcfce2e5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating use_with_caution split:   0%|          | 0/4439 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"abfb911852c5469dbbadd6c78f06abb7"}},"metadata":{}},{"name":"stdout","text":"Dataset loaded with 268211 samples\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# Data Exploration\n# Display a sample question\nsample_idx = 0\nprint(f\"Sample question: {dataset['train'][sample_idx]['question']}\")\nprint(f\"Sample solution: {dataset['train'][sample_idx]['solution']}\")\n\n# Check dataset structure\nprint(\"\\nDataset structure:\")\nprint(dataset['train'].column_names)\n\n# Display distribution of question types\nsubset_counts = dataset['train'].to_pandas()['subset'].value_counts()\nprint(\"\\nDistribution of question types:\")\nprint(subset_counts)","metadata":{"id":"5I2YaENa0Ej6","trusted":true,"execution":{"iopub.status.busy":"2025-03-20T14:36:14.602557Z","iopub.execute_input":"2025-03-20T14:36:14.602879Z","iopub.status.idle":"2025-03-20T14:36:30.643117Z","shell.execute_reply.started":"2025-03-20T14:36:14.602845Z","shell.execute_reply":"2025-03-20T14:36:30.642268Z"}},"outputs":[{"name":"stdout","text":"Sample question: Given a list of integers `nums`, find the maximum product of any two distinct elements in the list. Return the maximum product. For example, given `nums = [5, 3, -1, 9, -7]`, the maximum product would be `5 * 9 = 45`.\nSample solution: def max_product(nums):\n    \"\"\"\n    Returns the maximum product of any two distinct elements in the list.\n    \"\"\"\n    # Sort the list\n    nums.sort()\n    \n    # The maximum product could be from the two highest values or two lowest values (in case they are negative)\n    return max(nums[-1] * nums[-2], nums[0] * nums[1])\n\nDataset structure:\n['version', 'style', 'subset', 'question_id', 'question', 'solution', 'test', 'test_info', 'gpt_pass_sequence', 'gpt_pass_trial_num', 'gpt_difficulty', 'gpt_pass_percentage', 'r1_pass_sequence', 'r1_pass_trial_num', 'r1_correctness', 'r1_solution', 'metadata', 'conversations']\n\nDistribution of question types:\nsubset\nTaco              50917\nPrefill           33435\nFilter            29359\nLeetcode          23876\nData_Structure    23858\nAlgorithm         21641\nCode_Contests     19357\nCodeforces        18225\nApps              17434\nDocs              15863\nEvol               9567\nPackage            4679\nName: count, dtype: int64\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# Display difficulty distribution\ndifficulty_counts = dataset['train'].to_pandas()['gpt_difficulty'].value_counts()\nprint(\"\\nDistribution of difficulty levels:\")\nprint(difficulty_counts)","metadata":{"id":"d-tFhWx72nhr","trusted":true,"execution":{"iopub.status.busy":"2025-03-20T14:36:30.643894Z","iopub.execute_input":"2025-03-20T14:36:30.644213Z","iopub.status.idle":"2025-03-20T14:36:43.250752Z","shell.execute_reply.started":"2025-03-20T14:36:30.644188Z","shell.execute_reply":"2025-03-20T14:36:43.249880Z"}},"outputs":[{"name":"stdout","text":"\nDistribution of difficulty levels:\ngpt_difficulty\neasy      159623\nmedium     61856\nhard       46732\nName: count, dtype: int64\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# Data Preprocessing\ndef format_data_for_training(example):\n    \"\"\"Format the data for training with proper prompts and completions.\"\"\"\n    # Create a prompt in the format DeepSeek expects\n    prompt = f\"### Question:\\n{example['question']}\\n\\n### Solution:\\n\"\n    completion = example['solution']\n\n    # For our training, we'll combine prompt and completion\n    example['formatted_text'] = prompt + completion\n\n    return example\n\nprint(\"Formatting data for training...\")\nformatted_dataset = dataset['train'].map(format_data_for_training)\n\n# Split the dataset into training and validation sets\ntrain_val_data = formatted_dataset.train_test_split(test_size=0.1, seed=42)\ntrain_data = train_val_data['train']\nval_data = train_val_data['test']\n\nprint(f\"Training set size: {len(train_data)}\")\nprint(f\"Validation set size: {len(val_data)}\")","metadata":{"id":"FrQ1uU4X0Jn3","trusted":true,"execution":{"iopub.status.busy":"2025-03-20T14:36:43.251589Z","iopub.execute_input":"2025-03-20T14:36:43.251909Z","iopub.status.idle":"2025-03-20T14:37:48.368807Z","shell.execute_reply.started":"2025-03-20T14:36:43.251878Z","shell.execute_reply":"2025-03-20T14:37:48.367894Z"}},"outputs":[{"name":"stdout","text":"Formatting data for training...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/268211 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c6f1f092002d4cd284be1655298afd75"}},"metadata":{}},{"name":"stdout","text":"Training set size: 241389\nValidation set size: 26822\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"!pip install -U bitsandbytes","metadata":{"id":"OQt_PBJq7o__","trusted":true,"execution":{"iopub.status.busy":"2025-03-20T14:37:48.372600Z","iopub.execute_input":"2025-03-20T14:37:48.372819Z","iopub.status.idle":"2025-03-20T14:37:54.266675Z","shell.execute_reply.started":"2025-03-20T14:37:48.372799Z","shell.execute_reply":"2025-03-20T14:37:54.265546Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.10/dist-packages (0.45.3)\nRequirement already satisfied: torch<3,>=2.0 in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (2.5.1+cu121)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (1.26.4)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->bitsandbytes) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->bitsandbytes) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->bitsandbytes) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->bitsandbytes) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->bitsandbytes) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->bitsandbytes) (2.4.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.17.0)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch<3,>=2.0->bitsandbytes) (4.12.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch<3,>=2.0->bitsandbytes) (2024.12.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch<3,>=2.0->bitsandbytes) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch<3,>=2.0->bitsandbytes) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch<3,>=2.0->bitsandbytes) (3.0.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->bitsandbytes) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->bitsandbytes) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->bitsandbytes) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->bitsandbytes) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->bitsandbytes) (2024.2.0)\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# Model Setup\n# Load base model and tokenizer\nmodel_name = \"deepseek-ai/deepseek-coder-1.3b-base\"\n\nprint(f\"Loading model and tokenizer: {model_name}\")\ntokenizer = AutoTokenizer.from_pretrained(model_name)\ntokenizer.pad_token = tokenizer.eos_token\n\n# Setup 4-bit quantization for memory efficiency\nprint(\"Setting up 4-bit quantization...\")\nimport bitsandbytes as bnb\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_name,\n    torch_dtype=torch.float16,\n    device_map=\"auto\",\n    quantization_config={\n        \"load_in_4bit\": True,\n        \"bnb_4bit_compute_dtype\": torch.float16,\n        \"bnb_4bit_quant_type\": \"nf4\",\n        \"bnb_4bit_use_double_quant\": True,\n    }\n)\n\n# Configure LoRA adaptation\npeft_config = LoraConfig(\n    task_type=TaskType.CAUSAL_LM,\n    inference_mode=False,\n    r=8,\n    lora_alpha=32,\n    lora_dropout=0.1,\n    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\"]\n)\n\n# Prepare model for training\nprint(\"Preparing model for training...\")\nmodel = prepare_model_for_kbit_training(model)\nmodel = get_peft_model(model, peft_config)","metadata":{"id":"K2U3kKSe0OM0","trusted":true,"execution":{"iopub.status.busy":"2025-03-20T14:37:54.268393Z","iopub.execute_input":"2025-03-20T14:37:54.268632Z","iopub.status.idle":"2025-03-20T14:38:53.912066Z","shell.execute_reply.started":"2025-03-20T14:37:54.268611Z","shell.execute_reply":"2025-03-20T14:38:53.911109Z"}},"outputs":[{"name":"stdout","text":"Loading model and tokenizer: deepseek-ai/deepseek-coder-1.3b-base\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/793 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"59b82f392b214d309ced9a04a93501b6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.37M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b95ea2d1dceb4ec2a228d644de0226c9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/482 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a8ec0325dfa0448ea7668d0120556910"}},"metadata":{}},{"name":"stdout","text":"Setting up 4-bit quantization...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/631 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"437ceb17278e4117a884e8eb60716a1d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/2.69G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f57c57b50cef42e9b1b4d07456ead2e0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/119 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a2caff371c5d41459a1daff71e784ce5"}},"metadata":{}},{"name":"stdout","text":"Preparing model for training...\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# Tokenize the dataset\ndef tokenize_function(examples):\n    return tokenizer(\n        examples[\"formatted_text\"],\n        truncation=True,\n        max_length=2048,\n        padding=\"max_length\"\n    )\n\nprint(\"Tokenizing datasets...\")\ntokenized_train = train_data.map(\n    tokenize_function,\n    batched=True,\n    remove_columns=train_data.column_names\n)\n\ntokenized_val = val_data.map(\n    tokenize_function,\n    batched=True,\n    remove_columns=val_data.column_names\n)","metadata":{"id":"Ezspe9lT0UO2","trusted":true,"execution":{"iopub.status.busy":"2025-03-20T14:38:53.912932Z","iopub.execute_input":"2025-03-20T14:38:53.913201Z","iopub.status.idle":"2025-03-20T14:46:12.712987Z","shell.execute_reply.started":"2025-03-20T14:38:53.913178Z","shell.execute_reply":"2025-03-20T14:46:12.712283Z"}},"outputs":[{"name":"stdout","text":"Tokenizing datasets...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/241389 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"33a53807e2f34ec3ad22991169a98adb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/26822 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b01f30f8f6ae4a84b98fa9f4ddc5a964"}},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"# Training Configuration\ntraining_args = TrainingArguments(\n    output_dir=\"./results\",\n    num_train_epochs=3,\n    per_device_train_batch_size=2,\n    per_device_eval_batch_size=2,\n    gradient_accumulation_steps=8,\n    evaluation_strategy=\"steps\",\n    eval_steps=100,\n    save_steps=100,\n    warmup_steps=50,\n    learning_rate=2e-4,\n    weight_decay=0.01,\n    logging_dir=\"./logs\",\n    logging_steps=10,\n    save_total_limit=3,\n    load_best_model_at_end=True,\n    metric_for_best_model=\"eval_loss\",\n    greater_is_better=False,\n    fp16=True,\n    report_to=\"none\",\n)\n\n# Data collator\ndata_collator = DataCollatorForLanguageModeling(\n    tokenizer=tokenizer,\n    mlm=False\n)\n\n# Trainer\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_train,\n    eval_dataset=tokenized_val,\n    data_collator=data_collator,\n    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n)\n\n# Training\nprint(\"Starting training...\")\ntrainer.train()","metadata":{"id":"JLRVB6nN0aOY","trusted":true,"execution":{"iopub.status.busy":"2025-03-20T14:46:12.714300Z","iopub.execute_input":"2025-03-20T14:46:12.714639Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Starting training...\n","output_type":"stream"},{"name":"stderr","text":"`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n  return fn(*args, **kwargs)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='26' max='45258' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [   26/45258 24:38 < 773:58:23, 0.02 it/s, Epoch 0.00/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}}],"execution_count":null},{"cell_type":"code","source":"# Save the model\nprint(\"Saving model...\")\ntrainer.model.save_pretrained(\"./deepseek-r1-kodcode-finetuned\")\ntokenizer.save_pretrained(\"./deepseek-r1-kodcode-finetuned\")","metadata":{"id":"r5MUAmVl0fIs","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Evaluation\n# Define evaluation function\ndef evaluate_coding_task(model, tokenizer, question, max_length=2048):\n    prompt = f\"### Question:\\n{question}\\n\\n### Solution:\\n\"\n\n    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n\n    with torch.no_grad():\n        outputs = model.generate(\n            **inputs,\n            max_length=max_length,\n            num_return_sequences=1,\n            pad_token_id=tokenizer.eos_token_id\n        )\n\n    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n    solution = generated_text.split(\"### Solution:\\n\")[1].strip()\n\n    return solution\n\n# Evaluate the model on a sample of test questions\nprint(\"Evaluating model on sample test questions...\")\ntest_questions = dataset['train'].select(range(5))['question']  # Just using 5 samples for demonstration","metadata":{"id":"lAgT-w8v0hwL","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load the original model for comparison\nprint(\"Loading original model for comparison...\")\noriginal_model = AutoModelForCausalLM.from_pretrained(\n    model_name,\n    torch_dtype=torch.float16,\n    device_map=\"auto\",\n    load_in_4bit=True\n)\n\n# Compare solutions\nprint(\"Comparing solutions between original and fine-tuned models...\")\nfor i, question in enumerate(test_questions):\n    print(f\"\\nQuestion {i+1}:\")\n    print(question)\n\n    print(\"\\nOriginal model solution:\")\n    original_solution = evaluate_coding_task(original_model, tokenizer, question)\n    print(original_solution)\n\n    print(\"\\nFine-tuned model solution:\")\n    finetuned_solution = evaluate_coding_task(model, tokenizer, question)\n    print(finetuned_solution)","metadata":{"id":"G2IRC3Mj0leL","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cleanup\ndel original_model\ndel model\ngc.collect()\ntorch.cuda.empty_cache()\n\nprint(\"Evaluation complete!\")","metadata":{"id":"38LIZito0oHE","trusted":true},"outputs":[],"execution_count":null}]}